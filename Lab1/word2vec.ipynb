{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fd46618-ad8b-4641-9291-d545e2b01c09",
   "metadata": {},
   "source": [
    "# Word2Vec Assignment\n",
    "\n",
    "\n",
    "- Sagun Rupakheti st123431\n",
    "\n",
    "You MUST build on top of what we have coded in the class (to prevent anyone from just copying from the internet).\n",
    "\n",
    "1.  Try a real corpus (instead of banana apple, try something real... on the internet....) - not so big!  Just so you have a good taste of real stuff....like 50 documents, each having 50 words...(really up to you)\n",
    "\n",
    "2. Try a window size of 2\n",
    "\n",
    "3. Implement CBOW (instead of skipgrams)\n",
    "\n",
    "4. Compare normal version of skipgrams vs. negative sampling version of skipgrams in terms of time (using real corpus)\n",
    "\n",
    "Point criteria:\n",
    "0: not done/copy directly from your friend (inspired is ok)\n",
    "1: ok\n",
    "2: with comments, and a nice explanation along the notebook (like how Chaky do his tutorial...)\n",
    "\n",
    "Submit as GitHub link.\n",
    "\n",
    "**The solution starts from here--------**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df60ddca-f45e-4ee1-94be-22001e7bc915",
   "metadata": {},
   "source": [
    "**Embeddings are numerical representation i.e. a vector for words. The vectors try to capture the characteristics of the word which could be semantic or syntatic. Word2Vec is process of embedding used to group words together.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3134e809-bd57-4a53-9625-16ee1c5a7c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import some important libraries here\n",
    "# FYI, all libraries are compiled here\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "# import spacy\n",
    "import re\n",
    "import math \n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd306519-704a-4cf9-b69d-20f2bde3522c",
   "metadata": {},
   "source": [
    "# 1. Load the Data\n",
    "\n",
    "Let's load a corpus to start with the process of building models for Word2Vec. A corpus is a collection of authentic text or audio organized into datasets. In this notebook we use text data extracted from wikipedia on ChatGPT -> https://en.wikipedia.org/wiki/ChatGPT#:~:text=ChatGPT%20was%20fine,12%5D%5B13%5D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8517069a-68b1-4396-bcbe-419e3fc69990",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"data/data.txt\", \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be1093a6-e907-4e3d-80f8-60eac007e627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ChatGPT was fine-tuned on top of GPT-3.5 using supervised learning as well as reinforcement learning. [5] Both approaches used human trainers to improve the model's performance. In the case of supervised learning, the model was provided with conversations in which the trainers played both sides: the user and the AI assistant. In the reinforcement step, human trainers first ranked responses that the model had created in a previous conversation. These rankings were used to create 'reward models' that the model was further fine-tuned on using several iterations of Proximal Policy Optimization (PPO). [6][7] Proximal Policy Optimization algorithms present a cost-effective benefit to trust region policy optimization algorithms; they negate many of the computationally expensive operations with faster performance. [8][9] The models were trained in collaboration with Microsoft on their Azure supercomputing infrastructure.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4a4e620-be6d-40cb-a971-ede4a2a3090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting everything to be lower case \n",
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdc79422-eb25-4484-aa46-0738c756db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the corpus into a list of strings with each sentence as a string\n",
    "corpus = re.split(r\"\\. \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27514227-927e-4f43-93ed-7714281464c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chatgpt was fine-tuned on top of gpt-3.5 using supervised learning as well as reinforcement learning',\n",
       " \"[5] both approaches used human trainers to improve the model's performance\",\n",
       " 'in the case of supervised learning, the model was provided with conversations in which the trainers played both sides: the user and the ai assistant',\n",
       " 'in the reinforcement step, human trainers first ranked responses that the model had created in a previous conversation',\n",
       " \"these rankings were used to create 'reward models' that the model was further fine-tuned on using several iterations of proximal policy optimization (ppo)\",\n",
       " '[6][7] proximal policy optimization algorithms present a cost-effective benefit to trust region policy optimization algorithms; they negate many of the computationally expensive operations with faster performance',\n",
       " '[8][9] the models were trained in collaboration with microsoft on their azure supercomputing infrastructure.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82290248-de7e-465a-bca1-f5f98b673e11",
   "metadata": {},
   "source": [
    "### 1.1. Tokenization\n",
    "\n",
    "In this section, we split the sentences into words and store everything in a list. This splitting is called tokenizing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b211720e-9231-4c00-b579-a52d157bbdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['chatgpt',\n",
       "  'was',\n",
       "  'fine-tuned',\n",
       "  'on',\n",
       "  'top',\n",
       "  'of',\n",
       "  'gpt-3.5',\n",
       "  'using',\n",
       "  'supervised',\n",
       "  'learning',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'reinforcement',\n",
       "  'learning'],\n",
       " ['[5]',\n",
       "  'both',\n",
       "  'approaches',\n",
       "  'used',\n",
       "  'human',\n",
       "  'trainers',\n",
       "  'to',\n",
       "  'improve',\n",
       "  'the',\n",
       "  \"model's\",\n",
       "  'performance'],\n",
       " ['in',\n",
       "  'the',\n",
       "  'case',\n",
       "  'of',\n",
       "  'supervised',\n",
       "  'learning,',\n",
       "  'the',\n",
       "  'model',\n",
       "  'was',\n",
       "  'provided',\n",
       "  'with',\n",
       "  'conversations',\n",
       "  'in',\n",
       "  'which',\n",
       "  'the',\n",
       "  'trainers',\n",
       "  'played',\n",
       "  'both',\n",
       "  'sides:',\n",
       "  'the',\n",
       "  'user',\n",
       "  'and',\n",
       "  'the',\n",
       "  'ai',\n",
       "  'assistant'],\n",
       " ['in',\n",
       "  'the',\n",
       "  'reinforcement',\n",
       "  'step,',\n",
       "  'human',\n",
       "  'trainers',\n",
       "  'first',\n",
       "  'ranked',\n",
       "  'responses',\n",
       "  'that',\n",
       "  'the',\n",
       "  'model',\n",
       "  'had',\n",
       "  'created',\n",
       "  'in',\n",
       "  'a',\n",
       "  'previous',\n",
       "  'conversation'],\n",
       " ['these',\n",
       "  'rankings',\n",
       "  'were',\n",
       "  'used',\n",
       "  'to',\n",
       "  'create',\n",
       "  \"'reward\",\n",
       "  \"models'\",\n",
       "  'that',\n",
       "  'the',\n",
       "  'model',\n",
       "  'was',\n",
       "  'further',\n",
       "  'fine-tuned',\n",
       "  'on',\n",
       "  'using',\n",
       "  'several',\n",
       "  'iterations',\n",
       "  'of',\n",
       "  'proximal',\n",
       "  'policy',\n",
       "  'optimization',\n",
       "  '(ppo)'],\n",
       " ['[6][7]',\n",
       "  'proximal',\n",
       "  'policy',\n",
       "  'optimization',\n",
       "  'algorithms',\n",
       "  'present',\n",
       "  'a',\n",
       "  'cost-effective',\n",
       "  'benefit',\n",
       "  'to',\n",
       "  'trust',\n",
       "  'region',\n",
       "  'policy',\n",
       "  'optimization',\n",
       "  'algorithms;',\n",
       "  'they',\n",
       "  'negate',\n",
       "  'many',\n",
       "  'of',\n",
       "  'the',\n",
       "  'computationally',\n",
       "  'expensive',\n",
       "  'operations',\n",
       "  'with',\n",
       "  'faster',\n",
       "  'performance'],\n",
       " ['[8][9]',\n",
       "  'the',\n",
       "  'models',\n",
       "  'were',\n",
       "  'trained',\n",
       "  'in',\n",
       "  'collaboration',\n",
       "  'with',\n",
       "  'microsoft',\n",
       "  'on',\n",
       "  'their',\n",
       "  'azure',\n",
       "  'supercomputing',\n",
       "  'infrastructure.']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizing the corpus -> splitting all the words\n",
    "flatten = lambda l:[item for sublist in l for item in sublist]\n",
    "# flatten(corpus_tokenized)\n",
    "corpus_tokenized = [sent.split(\" \") for sent in corpus]\n",
    "corpus_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7a14cd7-1f19-4074-9421-c5fb9d53800d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['benefit',\n",
       " 'previous',\n",
       " 'responses',\n",
       " 'with',\n",
       " 'conversations',\n",
       " 'trainers',\n",
       " 'algorithms',\n",
       " 'azure',\n",
       " 'case',\n",
       " 'further',\n",
       " 'gpt-3.5',\n",
       " 'faster',\n",
       " '[8][9]',\n",
       " 'which',\n",
       " 'both',\n",
       " 'approaches',\n",
       " 'the',\n",
       " 'of',\n",
       " '[6][7]',\n",
       " 'these',\n",
       " 'many',\n",
       " 'learning,',\n",
       " 'several',\n",
       " 'improve',\n",
       " 'step,',\n",
       " 'created',\n",
       " 'human',\n",
       " \"models'\",\n",
       " 'algorithms;',\n",
       " 'provided',\n",
       " \"model's\",\n",
       " 'were',\n",
       " 'performance',\n",
       " 'infrastructure.',\n",
       " 'on',\n",
       " 'rankings',\n",
       " 'played',\n",
       " 'collaboration',\n",
       " 'as',\n",
       " 'optimization',\n",
       " 'models',\n",
       " 'operations',\n",
       " 'to',\n",
       " '(ppo)',\n",
       " 'chatgpt',\n",
       " 'reinforcement',\n",
       " 'assistant',\n",
       " 'microsoft',\n",
       " 'expensive',\n",
       " 'sides:',\n",
       " 'supercomputing',\n",
       " 'iterations',\n",
       " 'they',\n",
       " 'create',\n",
       " 'supervised',\n",
       " 'in',\n",
       " 'proximal',\n",
       " 'that',\n",
       " 'model',\n",
       " 'a',\n",
       " 'fine-tuned',\n",
       " 'ai',\n",
       " \"'reward\",\n",
       " 'their',\n",
       " 'policy',\n",
       " 'top',\n",
       " 'trained',\n",
       " 'trust',\n",
       " 'first',\n",
       " 'used',\n",
       " 'user',\n",
       " 'region',\n",
       " 'negate',\n",
       " 'conversation',\n",
       " 'was',\n",
       " 'cost-effective',\n",
       " 'ranked',\n",
       " 'well',\n",
       " 'present',\n",
       " 'learning',\n",
       " '[5]',\n",
       " 'had',\n",
       " 'using',\n",
       " 'and',\n",
       " 'computationally']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we take the tokenized corpus and select only the unique words \n",
    "# store it into a list called vocabs\n",
    "vocabs = list(set(flatten(corpus_tokenized)))\n",
    "vocabs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730eb49d-36f1-4f93-8c06-742aa638572c",
   "metadata": {},
   "source": [
    "### Numericalization\n",
    "- Here, we index all the words in the vocabs\n",
    "- Cause machine does not understand strings\n",
    "- For things to make sense for the machine, numbers are required\n",
    "- We will eventually add embeddings for all the indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40509f37-da5f-4b34-a0fa-dbcb33ad192d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'benefit': 0,\n",
       " 'previous': 1,\n",
       " 'responses': 2,\n",
       " 'with': 3,\n",
       " 'conversations': 4,\n",
       " 'trainers': 5,\n",
       " 'algorithms': 6,\n",
       " 'azure': 7,\n",
       " 'case': 8,\n",
       " 'further': 9,\n",
       " 'gpt-3.5': 10,\n",
       " 'faster': 11,\n",
       " '[8][9]': 12,\n",
       " 'which': 13,\n",
       " 'both': 14,\n",
       " 'approaches': 15,\n",
       " 'the': 16,\n",
       " 'of': 17,\n",
       " '[6][7]': 18,\n",
       " 'these': 19,\n",
       " 'many': 20,\n",
       " 'learning,': 21,\n",
       " 'several': 22,\n",
       " 'improve': 23,\n",
       " 'step,': 24,\n",
       " 'created': 25,\n",
       " 'human': 26,\n",
       " \"models'\": 27,\n",
       " 'algorithms;': 28,\n",
       " 'provided': 29,\n",
       " \"model's\": 30,\n",
       " 'were': 31,\n",
       " 'performance': 32,\n",
       " 'infrastructure.': 33,\n",
       " 'on': 34,\n",
       " 'rankings': 35,\n",
       " 'played': 36,\n",
       " 'collaboration': 37,\n",
       " 'as': 38,\n",
       " 'optimization': 39,\n",
       " 'models': 40,\n",
       " 'operations': 41,\n",
       " 'to': 42,\n",
       " '(ppo)': 43,\n",
       " 'chatgpt': 44,\n",
       " 'reinforcement': 45,\n",
       " 'assistant': 46,\n",
       " 'microsoft': 47,\n",
       " 'expensive': 48,\n",
       " 'sides:': 49,\n",
       " 'supercomputing': 50,\n",
       " 'iterations': 51,\n",
       " 'they': 52,\n",
       " 'create': 53,\n",
       " 'supervised': 54,\n",
       " 'in': 55,\n",
       " 'proximal': 56,\n",
       " 'that': 57,\n",
       " 'model': 58,\n",
       " 'a': 59,\n",
       " 'fine-tuned': 60,\n",
       " 'ai': 61,\n",
       " \"'reward\": 62,\n",
       " 'their': 63,\n",
       " 'policy': 64,\n",
       " 'top': 65,\n",
       " 'trained': 66,\n",
       " 'trust': 67,\n",
       " 'first': 68,\n",
       " 'used': 69,\n",
       " 'user': 70,\n",
       " 'region': 71,\n",
       " 'negate': 72,\n",
       " 'conversation': 73,\n",
       " 'was': 74,\n",
       " 'cost-effective': 75,\n",
       " 'ranked': 76,\n",
       " 'well': 77,\n",
       " 'present': 78,\n",
       " 'learning': 79,\n",
       " '[5]': 80,\n",
       " 'had': 81,\n",
       " 'using': 82,\n",
       " 'and': 83,\n",
       " 'computationally': 84}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "word2index = {v:idx for idx,v in enumerate(vocabs)}\n",
    "word2index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b4cdc2-99ea-44e0-ab69-207143d83fdf",
   "metadata": {},
   "source": [
    "We will add a new string called **UNK** to the vocab which will represent the words that are not in the scope of the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c7b4ef5-5ea4-47b9-bddb-46cd9dbd90f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index['<UNK>'] = 85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eea463b4-e0db-4032-8730-e3f7aa4bb4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs.append('<UNK>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a002bbd-1d86-46eb-af21-28d47f5757ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<UNK>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs[85]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeee3d9-d8f5-452a-bc50-7ddaa71561a3",
   "metadata": {},
   "source": [
    "# 2. Prepare the Data + Model + Test Model + Training + Plot Embeddings\n",
    "In this section, we use 3 methods for preparing the Data and for each methods, models are formulated<br>\n",
    "**2.1 CBow**<br>\n",
    "**2.2 Skipgram**<br>\n",
    "**2.3 Skipgram with Negative Sampling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2afe808-18e7-4c3f-a099-2c0b85b58c3f",
   "metadata": {},
   "source": [
    "### 2.1. CBow\n",
    "\n",
    "The main intuition behind CBow is it used to predict the center word using the context words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c7bdf2-3dc9-4816-8ee5-185d08d26d92",
   "metadata": {},
   "source": [
    "#### 2.1.1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9d5ae75-535e-455f-a6c8-e3636b892e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that creates batches of words\n",
    "# center and context words\n",
    "# adding window size to the function to make it flexible\n",
    "\n",
    "def cbow_random_batch(batch_size,corpus,window_size):\n",
    "    cbow = []\n",
    "    #for each corpus\n",
    "    for sent in corpus_tokenized:\n",
    "        #\n",
    "        for i in range(window_size,len(sent)-window_size): #start from 2 to second last\n",
    "            context_word = []\n",
    "            # print(sent[i])\n",
    "            center_word = word2index[sent[i]]\n",
    "            for j in range(window_size):\n",
    "                outside_word = [word2index[sent[i-j-1]],word2index[sent[i+j+1]]] #window_size adjustable\n",
    "                #loop through the outside to get all the context words in one list context word\n",
    "                for o in outside_word:\n",
    "                    context_word.append(o)\n",
    "                # append context and center word together\n",
    "                #Here, the context word will hold a list of words and center word is a single word\n",
    "                #cbow is a list of lists\n",
    "                cbow.append([context_word,center_word])\n",
    "    \n",
    "#     same as before\n",
    "    random_index = np.random.choice(range(len(cbow)),batch_size,replace=False)\n",
    "    #appending some list of inputs and labels\n",
    "    random_inputs, random_labels = [] , []\n",
    "    for index in random_index:\n",
    "        random_inputs.append([cbow[index][0]]) #center words, this will be as shape of (1,) -> (1,1) for modeling\n",
    "        random_labels.append([cbow[index][1]])\n",
    "    \n",
    "#     returning the inputs and labels\n",
    "    return np.array(random_inputs),np.array(random_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83069207-67c6-43af-bc93-469647b8be27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[16, 17, 55, 54]],\n",
       " \n",
       "        [[68,  2,  5, 57]]]),\n",
       " array([[ 8],\n",
       "        [76]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "batch_size=2\n",
    "cbow_random_batch(batch_size, corpus_tokenized,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ec4381-5a00-4299-85b9-a8af71f01c6c",
   "metadata": {},
   "source": [
    "### 2.1.2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f742c7b7-67e4-418e-8cc3-220b6731b589",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cbow(nn.Module):\n",
    "    \n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(Cbow, self).__init__()\n",
    "        self.embedding_center_word = nn.Embedding(voc_size, emb_size)  #is a lookup table mapping all ids in voc_size, into some vector of size emb_size\n",
    "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
    "        \n",
    "    def forward(self, center_word, outside_word, all_vocabs):\n",
    "        #center_word, outside_word: (batch_size, 1)\n",
    "        #all_vocabs: (batch_size, voc_size)\n",
    "        \n",
    "        #convert them into embedding\n",
    "        center_word_embed  = self.embedding_center_word(center_word)     #(batch_size, 1, emb_size)\n",
    "        outside_word_embed = self.embedding_outside_word(outside_word)   #(batch_size, 1, emb_size)\n",
    "        all_vocabs_embed   = self.embedding_outside_word(all_vocabs)     #(batch_size, voc_size, emb_size)\n",
    "        \n",
    "        #bmm is basically @ or .dot , but across batches (i.e., ignore the batch dimension)\n",
    "        top_term = outside_word_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
    "        #(batch_size, 1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) ===> (batch_size, 1)\n",
    "        \n",
    "        top_term_exp = torch.exp(top_term)  #exp(uo vc)\n",
    "        #(batch_size, 1)\n",
    "        \n",
    "        lower_term = all_vocabs_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
    "         #(batch_size, voc_size, emb_size) @ (batch_size, emb_size, 1) = (batch_size, voc_size, 1) = (batch_size, voc_size)\n",
    "         \n",
    "        # lower_term_sum = torch.sum(torch.exp(lower_term), 1) #sum exp(uw vc)\n",
    "        lower_term_sum = torch.sum(torch.exp(lower_term))\n",
    "        #(batch_size, 1)\n",
    "        \n",
    "        loss_fn = -torch.mean(torch.log(top_term_exp / lower_term_sum))\n",
    "        #(batch_size, 1) / (batch_size, 1) ==mean==> scalar\n",
    "        \n",
    "        return loss_fn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbd27de7-0399-49da-b0f4-6da26a38ff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size = len(vocabs)\n",
    "emb_size=2\n",
    "cbow_model = Cbow(voc_size,emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8373f42e-ba32-4909-9373-1d82cf2aba50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[72, 17, 52, 16]],\n",
       " \n",
       "        [[47, 63,  3,  7]],\n",
       " \n",
       "        [[ 4, 13,  3, 16]],\n",
       " \n",
       "        [[53, 27, 42, 57]],\n",
       " \n",
       "        [[72, 17, 52, 16]],\n",
       " \n",
       "        [[ 3, 34, 37, 63]],\n",
       " \n",
       "        [[39, 52, 64, 72]],\n",
       " \n",
       "        [[16, 74, 21, 29]],\n",
       " \n",
       "        [[42, 16,  5, 30]],\n",
       " \n",
       "        [[69, 53, 31, 62]]]),\n",
       " array([[20],\n",
       "        [34],\n",
       "        [55],\n",
       "        [62],\n",
       "        [20],\n",
       "        [47],\n",
       "        [28],\n",
       "        [58],\n",
       "        [23],\n",
       "        [42]]),\n",
       " 86)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WINDOW_SIZE=2\n",
    "\n",
    "input_cbow,label_cbow = cbow_random_batch(10,corpus,WINDOW_SIZE)\n",
    "input_cbow,label_cbow,voc_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c10840d9-cfab-44c7-b9a6-f8cd133a1db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to be long cause all tokens are integers\n",
    "input_tensor = torch.LongTensor(input_cbow)\n",
    "label_tensor = torch.LongTensor(label_cbow)  #LongTensor basically means integer...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "64ce5e41-25f3-43fe-bd08-9e55d975d6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 86])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "\n",
    "def prepare_sequence(seq, word2index):\n",
    "    #map(function, list of something)\n",
    "    #map will look at each of element in this list, and apply this function\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return torch.LongTensor(idxs)\n",
    "\n",
    "all_vocabs = prepare_sequence(list(vocabs), word2index).expand(batch_size, voc_size)\n",
    "all_vocabs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b8ac55f4-5948-40df-a973-095482f9bb70",
   "metadata": {},
   "outputs": [],
   "source": [
    " loss = cbow_model(input_tensor, label_tensor, all_vocabs)\n",
    "#Error - batch2 must be a 3D tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f208a2-7e46-4c2c-8927-158936509cc0",
   "metadata": {},
   "source": [
    "### 2.2 Skigram\n",
    "\n",
    "Here we create the random batch function\n",
    "The function is as same as done in the tutorial session so much explanation has not been done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "461f69e4-8db5-4977-8ab2-b469470b588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skipgram_random_batch(batch_size, corpus):\n",
    "    \n",
    "    skipgrams = []\n",
    "\n",
    "    #for each corpus\n",
    "    for sent in corpus_tokenized:\n",
    "        #for each sent [\"apple\", \"banana\", \"fruit\"]\n",
    "        for i in range(1, len(sent) - 1): #start from 1 to second last\n",
    "            center_word = word2index[sent[i]]\n",
    "            outside_words = [word2index[sent[i-1]], word2index[sent[i+1]]]  #window_size = 1\n",
    "            for o in outside_words:\n",
    "                skipgrams.append([center_word, o])\n",
    "                \n",
    "    #only get a batch, not the entire list\n",
    "    random_index = np.random.choice(range(len(skipgrams)), batch_size, replace=False)\n",
    "             \n",
    "    #appending some list of inputs and labels\n",
    "    random_inputs, random_labels = [], []   \n",
    "    for index in random_index:\n",
    "        random_inputs.append([skipgrams[index][0]])  #center words, this will be a shape of (1, ) --> (1, 1) for modeling\n",
    "        random_labels.append([skipgrams[index][1]])\n",
    "        \n",
    "    return np.array(random_inputs), np.array(random_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a0095d0-bd78-4dc5-89a5-8269b80cdc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n",
      "label=array([[51],\n",
      "       [16],\n",
      "       [34],\n",
      "       [49],\n",
      "       [83],\n",
      "       [79],\n",
      "       [68],\n",
      "       [12],\n",
      "       [23],\n",
      "       [35]])\n"
     ]
    }
   ],
   "source": [
    "input, label = skipgram_random_batch(10, corpus_tokenized)\n",
    "\n",
    "print(f\"{input.shape}\")\n",
    "print(f\"{label=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af3b45b-07e4-495a-9087-118891f016c7",
   "metadata": {},
   "source": [
    "### 2.2.2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b4c15c9-ecc3-4faf-a99a-02bc8556130e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_size = len(vocabs)\n",
    "voc_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fd62ec1-dedd-49cf-a394-ef443588996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model will accept three vectors - u_o, v_c, u_w\n",
    "#u_o - vector for outside words\n",
    "#v_c - vector for center word\n",
    "#u_w - vectors of all vocabs\n",
    "\n",
    "class Skipgram(nn.Module):\n",
    "    \n",
    "    def __init__(self, voc_size, emb_size):\n",
    "        super(Skipgram, self).__init__()\n",
    "        self.embedding_center_word  = nn.Embedding(voc_size, emb_size)  #is a lookup table mapping all ids in voc_size, into some vector of size emb_size\n",
    "        self.embedding_outside_word = nn.Embedding(voc_size, emb_size)\n",
    "    \n",
    "    def forward(self, center_word, outside_word, all_vocabs):\n",
    "        #center_word, outside_word: (batch_size, 1)\n",
    "        #all_vocabs: (batch_size, voc_size)\n",
    "        \n",
    "        #convert them into embedding\n",
    "        center_word_embed  = self.embedding_center_word(center_word)     #(batch_size, 1, emb_size)\n",
    "        outside_word_embed = self.embedding_outside_word(outside_word)   #(batch_size, 1, emb_size)\n",
    "        all_vocabs_embed   = self.embedding_outside_word(all_vocabs)     #(batch_size, voc_size, emb_size)\n",
    "        \n",
    "        #bmm is basically @ or .dot , but across batches (i.e., ignore the batch dimension)\n",
    "        top_term = outside_word_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
    "        #(batch_size, 1, emb_size) @ (batch_size, emb_size, 1) = (batch_size, 1, 1) ===> (batch_size, 1)\n",
    "        \n",
    "        top_term_exp = torch.exp(top_term)  #exp(uo vc)\n",
    "        #(batch_size, 1)\n",
    "        \n",
    "        lower_term = all_vocabs_embed.bmm(center_word_embed.transpose(1, 2)).squeeze(2)\n",
    "         #(batch_size, voc_size, emb_size) @ (batch_size, emb_size, 1) = (batch_size, voc_size, 1) = (batch_size, voc_size)\n",
    "         \n",
    "        lower_term_sum = torch.sum(torch.exp(lower_term), 1) #sum exp(uw vc)\n",
    "        #(batch_size, 1)\n",
    "        \n",
    "        loss_fn = -torch.mean(torch.log(top_term_exp / lower_term_sum))\n",
    "        #(batch_size, 1) / (batch_size, 1) ==mean==> scalar\n",
    "        \n",
    "        return loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff470641-57be-49d1-a1a8-a87e697d1211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 86])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "\n",
    "def prepare_sequence(seq, word2index):\n",
    "    #map(function, list of something)\n",
    "    #map will look at each of element in this list, and apply this function\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return torch.LongTensor(idxs)\n",
    "\n",
    "all_vocabs = prepare_sequence(list(vocabs), word2index).expand(batch_size, voc_size)\n",
    "all_vocabs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8e79545-2ec3-436f-8fa0-d09f0c67c3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54],\n",
       "       [39]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input, label = skipgram_random_batch(batch_size, corpus_tokenized)\n",
    "input\n",
    "# input #center word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b32b4766-8e34-4f16-84a0-6e285b648267",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 2 #usually, this can be 50, 100, or 300\n",
    "model = Skipgram(voc_size, emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76d5f729-9430-46a9-95ce-21102edcb6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.LongTensor(input)  \n",
    "label_tensor = torch.LongTensor(label)  #LongTensor basically means integer...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b45c7529-62f6-4075-9ca6-136d8f86a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model(input_tensor, label_tensor, all_vocabs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e997c7cd-8613-4784-9fd3-1ceaedfceaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.1596, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df4be5c-ead6-413c-8398-b05226806f75",
   "metadata": {},
   "source": [
    "### 2.2.3 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c75acea0-fa05-4338-90c5-0ad5b9cb9182",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2 #why?  no reason; \n",
    "emb_size   = 2 #why?  no reason; usually 50, 100, 300, but 2 so we can plot (50 can also plot, but need PCA)\n",
    "skipgram_model      = Skipgram(voc_size, emb_size)\n",
    "\n",
    "optimizer  = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa1b746c-868d-4bfa-90b7-63741cfecb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from Chaky's lecture notebook on skipgram with scratch\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46040117-85b4-4691-b7b3-48db0384cc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000 | cost: 4.744878 | time: 0m 1s\n",
      "Epoch: 2000 | cost: 6.116297 | time: 0m 2s\n",
      "Epoch: 3000 | cost: 4.925833 | time: 0m 3s\n",
      "Epoch: 4000 | cost: 4.273641 | time: 0m 5s\n",
      "Epoch: 5000 | cost: 4.504857 | time: 0m 6s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Training\n",
    "num_epochs = 5000\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    \n",
    "    \n",
    "    input_batch, target_batch = skipgram_random_batch(batch_size, corpus)\n",
    "    input_batch  = torch.LongTensor(input_batch)  #[batch_size, 1]\n",
    "    target_batch = torch.LongTensor(target_batch) #[batch_size, 1]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = skipgram_model(input_batch, target_batch, all_vocabs)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231d1a0d-b0fa-48b7-821f-4391bdb250da",
   "metadata": {},
   "source": [
    "### 2.2.4. Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84ed3f9a-a480-4968-8ed6-e86059eae1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed(word):\n",
    "    try:\n",
    "        index = word2index[word]\n",
    "    except:\n",
    "        index = word2index['<UNK>']\n",
    "    \n",
    "    word = torch.LongTensor([index])\n",
    "\n",
    "    center_embed  = skipgram_model.embedding_center_word(word)\n",
    "    outside_embed = skipgram_model.embedding_outside_word(word)\n",
    "    \n",
    "    embed = (center_embed + outside_embed) / 2\n",
    "    \n",
    "    return  embed[0][0].item(), embed[0][1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b756fb54-2d4a-4e99-b452-7e4324d982c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "for i, word in enumerate(vocabs[:20]): #loop each unique vocab\n",
    "    x, y = get_embed(word)\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822978ff-71c1-4e1a-8f13-174e23ae0073",
   "metadata": {},
   "source": [
    "### 2.3 Negative sampling Skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d96ed9e3-7796-42e6-94f9-bd622dc3ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sampling_random_batch(batch_size, word_sequence):\n",
    "    \n",
    "    # Make skip gram of one size window\n",
    "    skip_grams = []\n",
    "    # loop each word sequence\n",
    "    # we starts from 1 because 0 has no context\n",
    "    # we stop at second last for the same reason\n",
    "    for sent in corpus_tokenized:\n",
    "        for i in range(1, len(sent) - 1):\n",
    "            target = word2index[sent[i]]\n",
    "            context = [word2index[sent[i - 1]], word2index[sent[i + 1]]]\n",
    "            for w in context:\n",
    "                skip_grams.append([target, w])\n",
    "    \n",
    "    random_inputs = []\n",
    "    random_labels = []\n",
    "    random_index = np.random.choice(range(len(skip_grams)), batch_size, replace=False) #randomly pick without replacement\n",
    "        \n",
    "    for i in random_index:\n",
    "        random_inputs.append([skip_grams[i][0]])  # target, e.g., 2\n",
    "        random_labels.append([skip_grams[i][1]])  # context word, e.g., 3\n",
    "            \n",
    "    return np.array(random_inputs), np.array(random_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a74d9f71-df76-41e5-9052-611ea1d90cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  [[17]\n",
      " [78]]\n",
      "Target:  [[56]\n",
      " [ 6]]\n"
     ]
    }
   ],
   "source": [
    "#testing the method\n",
    "batch_size = 2 # mini-batch size\n",
    "input_batch, target_batch = negative_sampling_random_batch(batch_size, corpus)\n",
    "\n",
    "print(\"Input: \",  input_batch)\n",
    "print(\"Target: \", target_batch)\n",
    "\n",
    "#we will convert them to tensor during training, so don't worry..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52c7cdda-20e9-47fc-a6be-187335fabf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 1), (2, 1))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_batch.shape, target_batch.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48b0c7f-1e1e-4c20-bf96-e9086b7c6861",
   "metadata": {},
   "source": [
    "## 2.3.1. Unigram Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8cefe354-a3bf-4eea-90d8-ffea98895bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_count = Counter(flatten(corpus_tokenized))\n",
    "num_total_words = sum([c for w, c in word_count.items()])\n",
    "word_count[',']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1350239e-225b-4530-8f71-78f6be23e466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count[',']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "514a7565-8089-4bf6-994e-38ef02c2f847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81fd3068-de89-4659-9383-8fa0a35b7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = 0.001\n",
    "\n",
    "unigram_table = []\n",
    "\n",
    "for vo in vocabs:\n",
    "    unigram_table.extend([vo] * int(((word_count[vo]/num_total_words)**0.75)/Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ee2774b-8a4e-4934-bbf2-05e7c0f922a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'benefit': 25,\n",
       "         'previous': 25,\n",
       "         'responses': 25,\n",
       "         'with': 58,\n",
       "         'conversations': 25,\n",
       "         'trainers': 58,\n",
       "         'algorithms': 25,\n",
       "         'azure': 25,\n",
       "         'case': 25,\n",
       "         'further': 25,\n",
       "         'gpt-3.5': 25,\n",
       "         'faster': 25,\n",
       "         '[8][9]': 25,\n",
       "         'which': 25,\n",
       "         'both': 43,\n",
       "         'approaches': 25,\n",
       "         'the': 155,\n",
       "         'of': 72,\n",
       "         '[6][7]': 25,\n",
       "         'these': 25,\n",
       "         'many': 25,\n",
       "         'learning,': 25,\n",
       "         'several': 25,\n",
       "         'improve': 25,\n",
       "         'step,': 25,\n",
       "         'created': 25,\n",
       "         'human': 43,\n",
       "         \"models'\": 25,\n",
       "         'algorithms;': 25,\n",
       "         'provided': 25,\n",
       "         \"model's\": 25,\n",
       "         'were': 43,\n",
       "         'performance': 43,\n",
       "         'infrastructure.': 25,\n",
       "         'on': 58,\n",
       "         'rankings': 25,\n",
       "         'played': 25,\n",
       "         'collaboration': 25,\n",
       "         'as': 43,\n",
       "         'optimization': 58,\n",
       "         'models': 25,\n",
       "         'operations': 25,\n",
       "         'to': 58,\n",
       "         '(ppo)': 25,\n",
       "         'chatgpt': 25,\n",
       "         'reinforcement': 43,\n",
       "         'assistant': 25,\n",
       "         'microsoft': 25,\n",
       "         'expensive': 25,\n",
       "         'sides:': 25,\n",
       "         'supercomputing': 25,\n",
       "         'iterations': 25,\n",
       "         'they': 25,\n",
       "         'create': 25,\n",
       "         'supervised': 43,\n",
       "         'in': 85,\n",
       "         'proximal': 43,\n",
       "         'that': 43,\n",
       "         'model': 58,\n",
       "         'a': 43,\n",
       "         'fine-tuned': 43,\n",
       "         'ai': 25,\n",
       "         \"'reward\": 25,\n",
       "         'their': 25,\n",
       "         'policy': 58,\n",
       "         'top': 25,\n",
       "         'trained': 25,\n",
       "         'trust': 25,\n",
       "         'first': 25,\n",
       "         'used': 43,\n",
       "         'user': 25,\n",
       "         'region': 25,\n",
       "         'negate': 25,\n",
       "         'conversation': 25,\n",
       "         'was': 58,\n",
       "         'cost-effective': 25,\n",
       "         'ranked': 25,\n",
       "         'well': 25,\n",
       "         'present': 25,\n",
       "         'learning': 43,\n",
       "         '[5]': 25,\n",
       "         'had': 25,\n",
       "         'using': 43,\n",
       "         'and': 25,\n",
       "         'computationally': 25})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(unigram_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9bb8c638-436d-4550-a22a-ec9a5b742dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_sequence(seq, word2index):\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return torch.LongTensor(idxs)\n",
    "\n",
    "def negative_sampling(targets, unigram_table, k):\n",
    "    batch_size = targets.size(0)\n",
    "    neg_samples = []\n",
    "    for i in range(batch_size):\n",
    "        nsample = []\n",
    "        target_index = targets[i].item()\n",
    "        while len(nsample) < k: # num of sampling\n",
    "            neg = random.choice(unigram_table)\n",
    "            if word2index[neg] == target_index:\n",
    "                continue\n",
    "            nsample.append(neg)\n",
    "        neg_samples.append(prepare_sequence(nsample, word2index).view(1, -1))\n",
    "    \n",
    "    return torch.cat(neg_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f1f59376-c665-4319-bda3-840bb49b7284",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch  = torch.Tensor(input_batch)\n",
    "target_batch = torch.LongTensor(target_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d4946bcd-64e7-4eb1-9546-c71c8727fd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_batch.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d2003b9-7da0-4471-afcf-6a0e19fb3ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18, 14, 81],\n",
       "        [32, 54, 58]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_neg = 3\n",
    "negative_sampling(target_batch, unigram_table, num_neg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ad0c73-b7fb-4631-b16e-a5911dd409a9",
   "metadata": {},
   "source": [
    "## 2.3.2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "176e94e8-a620-4c16-ac4e-0f849f7b8747",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipgramNegSampling(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        super(SkipgramNegSampling, self).__init__()\n",
    "        self.embedding_v = nn.Embedding(vocab_size, emb_size) # center embedding\n",
    "        self.embedding_u = nn.Embedding(vocab_size, emb_size) # out embedding\n",
    "        self.logsigmoid = nn.LogSigmoid()\n",
    "                    \n",
    "    def forward(self, center_words, target_words, negative_words):\n",
    "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
    "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
    "        neg_embeds    = -self.embedding_u(negative_words) # [batch_size, num_neg, emb_size]\n",
    "        \n",
    "        positive_score = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
    "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
    "        \n",
    "        negative_score = neg_embeds.bmm(center_embeds.transpose(1, 2))\n",
    "        #[batch_size, k, emb_size] @ [batch_size, emb_size, 1] = [batch_size, k, 1]\n",
    "        \n",
    "        loss = self.logsigmoid(positive_score) + torch.sum(self.logsigmoid(negative_score), 1)\n",
    "                \n",
    "        return -torch.mean(loss)\n",
    "    \n",
    "    def prediction(self, inputs):\n",
    "        embeds = self.embedding_v(inputs)\n",
    "        \n",
    "        return embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75c3b9b-9e31-4e62-bb41-5dff613f7228",
   "metadata": {},
   "source": [
    "## 2.3.3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "abd2e73f-7888-4710-8ae9-c8fc45fefedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size     = 2 # mini-batch size\n",
    "embedding_size = 2 #so we can later plot\n",
    "model_neg_skip          = SkipgramNegSampling(voc_size, embedding_size)\n",
    "num_neg        = 10 # num of negative sampling\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1cd62a78-ee91-4d65-86d5-39fec5361c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "359b6a51-92ff-474f-a79f-b69145162f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000 | cost: 6.815511 | time: 0m 1s\n",
      "Epoch: 2000 | cost: 12.398777 | time: 0m 3s\n",
      "Epoch: 3000 | cost: 8.263274 | time: 0m 4s\n",
      "Epoch: 4000 | cost: 9.889107 | time: 0m 6s\n",
      "Epoch: 5000 | cost: 14.295798 | time: 0m 7s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Training\n",
    "num_epochs = 5000\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    input_batch, target_batch = negative_sampling_random_batch(batch_size, corpus)\n",
    "    \n",
    "    #input_batch: [batch_size, 1]\n",
    "    input_batch = torch.LongTensor(input_batch)\n",
    "    \n",
    "    #target_batch: [batch_size, 1]\n",
    "    target_batch = torch.LongTensor(target_batch)\n",
    "    \n",
    "    #negs_batch:   [batch_size, num_neg]\n",
    "    negs_batch = negative_sampling(target_batch, unigram_table, num_neg)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "        \n",
    "    loss = model_neg_skip(input_batch, target_batch, negs_batch)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b422446-b2fb-4911-bf88-6f7e4bc82858",
   "metadata": {},
   "source": [
    "## Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aa8ca2ea-e101-4c89-b83a-1092f8befc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_embed(word):\n",
    "    id_tensor = torch.LongTensor([word2index[word]])\n",
    "    v_embed = model_neg_skip.embedding_v(id_tensor)\n",
    "    u_embed = model_neg_skip.embedding_u(id_tensor) \n",
    "    word_embed = (v_embed + u_embed) / 2 \n",
    "    x, y = word_embed[0][0].item(), word_embed[0][1].item()\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac4d6d3-a289-49df-ac5a-1b3b1fe127cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "for i, word in enumerate(vocabs[:20]): #loop each unique vocab\n",
    "    x, y = get_embed(word)\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
